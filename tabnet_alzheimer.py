# -*- coding: utf-8 -*-
"""resnet_alzheimer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LzY0qEUVpOk09H_FjMmmN98ZRBY7tSwm
"""

!pip install pytorch-tabnet

#Importing Models
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import SGDClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from lightgbm import LGBMClassifier
from xgboost.sklearn import XGBClassifier


import matplotlib.pyplot as plt
from matplotlib import pyplot
import numpy as np
import pandas as pd
import os
from sklearn.preprocessing import StandardScaler
from sklearn.metrics  import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
import sklearn
from sklearn.model_selection import StratifiedKFold
print(sklearn.__version__)

from google.colab import drive
drive.mount('/content/gdrive')
datapath="/content/gdrive/My Drive"

df = pd.read_csv(os.path.join(datapath,'Alzheimer_Data.csv'))
df = df.drop(["SubjectID"], axis=1)
df.head()

print("HC Patients: ", df["Diagnosis (0 - HC, 1 - MCI, 2 - AD)"].value_counts()[0])
print("MCI Patients: ", df["Diagnosis (0 - HC, 1 - MCI, 2 - AD)"].value_counts()[1])
print("AD Patients: ", df["Diagnosis (0 - HC, 1 - MCI, 2 - AD)"].value_counts()[2])
print("Total Patients: ", df["Diagnosis (0 - HC, 1 - MCI, 2 - AD)"].value_counts()[0]+df["Diagnosis (0 - HC, 1 - MCI, 2 - AD)"].value_counts()[1]+df["Diagnosis (0 - HC, 1 - MCI, 2 - AD)"].value_counts()[2])

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from pytorch_tabnet.tab_model import TabNetClassifier
import torch

# Load your dataset and preprocess it
# Replace this part with your actual dataset loading and preprocessing steps

# For demonstration, let's use the Iris dataset as an example

label_encoder = LabelEncoder()
df['Diagnosis (0 - HC, 1 - MCI, 2 - AD)'] = label_encoder.fit_transform(df['Diagnosis (0 - HC, 1 - MCI, 2 - AD)'])
X = df.drop('Diagnosis (0 - HC, 1 - MCI, 2 - AD)', axis=1).values
y = df['Diagnosis (0 - HC, 1 - MCI, 2 - AD)'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Define TabNetClassifier model
clf = TabNetClassifier(optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2), scheduler_params=dict(mode="min"),
                       scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau, verbose=1,
                       epsilon=1e-15, seed=42, clip_value=2.0)

# Fit the model
clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], patience=10, max_epochs=100)

# Print training history to inspect available keys and their structure
print(clf.history.history)

# Make predictions
y_pred = clf.predict(X_test)

# Decode predictions (if needed)
y_pred_decoded = label_encoder.inverse_transform(y_pred)

# Print classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_decoded))